---
title: "Project Timeline"
---

This timeline traces the evolution of the Accessible IoT project from its inception in 2021 through completion in 2025. Each year brought new focus areas, prototypes, and research contributions that together built a comprehensive approach to accessible IoT design.

## 2021: Foundation Phase

**Focus**: Establishing sensing approaches and initial prototypes

### Key Achievements

The project launched with JST Presto Grant JPMJPR2132, establishing our core vision: Open Accessibility Assessment Toolkits for Inclusive IoT Design. We began exploring how physiological sensing could be seamlessly integrated into everyday objects to enable unobtrusive accessibility assessment.

Our first major prototype, the Affective Umbrella, demonstrated the feasibility of capturing galvanic skin response and heart rate data from an umbrella handle. This work established technical foundations showing that everyday objects could provide physiological measurements comparable to laboratory-grade equipment, while also exploring how real-time bio-feedback visualization could support emotion regulation through somaesthetic appreciation.

We also launched Ethereal Phenomena, an interactive art installation exploring meditation and breathing biofeedback. This work expanded our exploration beyond purely functional accessibility tools to consider how aesthetic and contemplative experiences could contribute to wellbeing and stress management—addressing accessibility not just as removing barriers but as enhancing quality of life.

### Publications (2 papers)

- **chen2021affective**: Affective Umbrella - Towards a Novel Sensor Integrated Multimedia Platform Using Electrodermal and Heart Activity in an Umbrella Handle (MUM 2021)
- **malaver2021ethereal**: Ethereal Phenomena (SIGGRAPH Asia 2021 Art Gallery)

---

## 2022: Expansion Phase

**Focus**: Visual accessibility and theoretical foundations

### Key Achievements

The second year marked significant expansion in both technical capabilities and theoretical grounding. We launched "Seeing Our Blind Spots"—optical see-through smart glasses enabling dynamic visual impairment simulation. This prototype demonstrated how experiential learning tools could increase designers' awareness of accessibility challenges, shifting our approach to include not just assessment but also education and empathy-building.

Concurrently, we contributed to theoretical foundations through a comprehensive survey on Human-Computer Integration published in Foundations and Trends, establishing conceptual frameworks that would inform our subsequent technical work. This publication helped position our research within broader discussions about how computational systems can become more deeply integrated with human capabilities and experiences.

We also explored pneumatic gel muscles for augmenting plantar flexor muscle stretching in children with cerebral palsy, demonstrating the applicability of soft robotics and haptic feedback to accessibility challenges. Additionally, our work on EOG-based authentication using smart glasses showed how physiological signals could serve multiple purposes—both assessment and interaction.

### Publications (4 papers)

- ⭐ **zhang2022seeing**: Seeing Our Blind Spots - Smart Glasses-based Simulation to Increase Design Students' Awareness of Visual Impairment (UIST 2022)
- ⭐ **semertzidis2022human**: Human-Computer Integration: Towards Integrating the Human Body with the Computational Machine (Foundations and Trends in HCI 2022)
- **chen2022towards**: Towards Applying Pneumatic Gel Muscles to Augment Plantar Flexor Muscle Stretching for Children with Cerebral Palsy (Augmented Humans 2022)
- **ragozin2022eyemove**: EyeMove - Towards Mobile Authentication using EOG Glasses (Augmented Humans 2022)
- **malaver2022ethereal**: Ethereal Phenomena - Interactive Art, Meditation, and Breathing Biofeedback: From Mind and Body Wellness Towards Self-Transcendence (TEI 2022)

---

## 2023: Community Engagement

**Focus**: Real-world deployments and co-design with disabled communities

### Key Achievements

The third year emphasized community partnerships and real-world deployments, reflecting our commitment to co-design with disabled communities rather than designing for them. We established collaborative relationships with volunteering organizations supporting leisure sports for visually impaired individuals, beginning the ethnographic research that would inform our understanding of guided running.

We also deployed robotic telepresence systems in an actual café staffed by disabled workers, demonstrating how assistive robotics could create new employment opportunities. This work exemplified our approach of validating research through authentic deployments in everyday contexts rather than controlled laboratory settings.

The Affective Umbrella research matured into a comprehensive wearable system evaluated in real-world conditions (rainy weather at night), producing validated findings about somaesthetic appreciation and emotion regulation. This milestone demonstrated that our sensing approaches could transition from proof-of-concept prototypes to systems robust enough for genuine field deployment.

### Publications (2 papers)

- ⭐ **barbareschi2023robotic**: "I am both here and there" - Parallel Control of Multiple Robotic Avatars by Disabled Workers in a Café (CHI 2023)
- **chen2023affective**: Affective Umbrella - A Wearable System to Visualize Heart and Electrodermal Activity, towards Emotion Regulation through Somaesthetic Appreciation (Augmented Humans 2023)
- **li2023first**: First Bite/Chew - Distinguish Typical Allergic Food by Two IMUs (Augmented Humans 2023)

---

## 2024: Platform Development

**Focus**: Open-source platforms and methodological expansion

### Key Achievements

The fourth year focused on creating open-source platforms that would democratize access to our sensing approaches and findings. We released OpenEarable ExG, the first open-source hardware platform specifically designed for ear-based biopotential sensing. By releasing complete designs, firmware, and documentation under MIT license with OSHWA certification, we lowered barriers for other researchers and developers to explore accessible wearable technologies.

Our research on visually impaired runners culminated in publication at CHI 2024, presenting a comprehensive framework for understanding interdependent collaboration during guided running. This work demonstrated the value of extended ethnographic engagement, revealing sophisticated communication practices that inform how technology should support rather than replace existing strategies.

We also launched the mobiCHAI workshop series (Mobile Cognitive-Augmenting and Cognition-Altering Technologies in Human-Centered AI) at MobileHCI, creating a new community forum for discussing cognitive augmentation approaches. Additionally, our exploration of vocal technique sensing using EMG and ultrasonography opened new directions for physiological assessment.

### Publications (3 papers)

- ⭐ **barbareschi2024speech**: "Speech is Silver, Silence is Golden" - Analyzing Micro-communication Strategies between Visually Impaired Runners and their Guides (CHI 2024)
- ⭐ **lepold2024openarable**: OpenEarable ExG - Open-Source Hardware for Ear-Based Biopotential Sensing Applications (UbiComp 2024)
- **chen2024novel**: A Novel Sensing Method and Its Empirical Study for Vocal Technique Analysis of Singing Pitch Control: Combining Surface EMG with Ultrasonography (Augmented Humans 2024)
- **elagroudy2024mobichai**: mobiCHAI 2024 - 1st International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (MobileHCI 2024)

---

## 2025: Integration and Dissemination

**Focus**: Synthesis, community building, and future directions

### Key Achievements

The final year demonstrated the breadth and maturity of our research program through 10 publications spanning diverse topics while maintaining thematic coherence. Major achievements included MindSpace (a pneumatic haptic device for relaxation breaks) and multiple contributions to vocal sensing and training systems, showing how our physiological sensing approaches could address varied accessibility challenges.

We expanded our community-building efforts through the 2nd mobiCHAI workshop and additional events at Augmented Humans and UbiComp. We also organized two Dagstuhl Seminars on Cognitive Augmentation, bringing together international leaders to define future research agendas.

The year's publications reflected increasing sophistication in our sensing methods (multimodal vocal training systems, physiological insights for breath-aware augmentation), expanding application domains (singing training, meditation augmentation, haptic VR navigation), and continued platform development (soft floating robotic avatars, biosensing workshops). This diversity demonstrated that our two-pronged approach—helping users through sensing and supporting designers through simulation—could generate rich research contributions across multiple dimensions of accessible IoT.

### Publications (10 papers)

Major research themes this year included:
- **Haptic feedback and stress relief**: MindSpace, meditation augmentation, EchoSense VR navigation
- **Vocal sensing and training**: Multimodal wearable systems, breath analysis, VCSD dataset
- **Community building**: 2nd mobiCHAI workshop, biosensing workshop
- **Assistive robotics**: Spread Your Wings soft floating robot
- **Skill learning and training**: Pro's Eyes observational learning system

**Full publication list**:
- **kikuchi2025mindspace**: MindSpace - Improving Relaxation Break and Performance Using a Device Exerting Tactile Sensation of Life-like Breathing Movement (Mensch und Computer 2025)
- **peng2025echosense**: EchoSense - Frontal Haptic Navigation in VR towards Biomimetic Empathy (UbiComp 2025)
- **peng2025conscious**: Conscious or Unconscious Meditation? Haptic Interaction Design in Meditation Augmentation Using Physiological Sensing (UbiComp 2025)
- **chen2025multimodal**: A Multimodal Wearable Sensing System for Vocal Muscle Biofeedback in Singing Pitch Training (UbiComp 2025)
- **chen2025exploring**: Exploring Singing Breath - Physiological Insights and Directions for Breath-Aware Augmentation in Mixed Reality Design (UbiComp 2025)
- **chen2025introduction**: Introduction of the VCSD Dataset - A Vocal Cords Dataset Using EMG and Ultrasonography for Singing Pitch Skill Recognition (UbiComp 2025)
- **xu2025spread**: Spread Your Wings - Demonstrating a Soft Floating Robotic Avatar with Flapping Wings for Novel Physical Interactions (SIGGRAPH 2025 Emerging Technologies)
- **zhang2025pro**: Pro's Eyes - A Wearable System for Synchronous and Asynchronous Observational Pattern Learning (SIGGRAPH Asia 2025 Emerging Technologies)
- **gruenerbl20252nd**: 2nd International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies in Human-Centered AI (MobileHCI 2025)
- **hakkila2025biosensing**: Biosensing, Enhanced Senses and Experience Design for Augmented Humans (UbiComp 2025 Workshop)

---

## Overall Impact (2021-2025)

### Quantitative Metrics

- **30 publications** in top-tier international venues
- **40+ citations** (Google Scholar) demonstrating research influence
- **19 research themes** explored across the project
- **4 major prototypes** developed and validated (Affective Umbrella, MindSpace, Visual Impairment Glasses, OpenEarable ExG)
- **2 open-source platforms** released with complete documentation
- **6 international workshops** organized at major conferences

### Qualitative Impact

**Research Contributions**: Established foundations for dynamic, in-situ accessibility assessment using physiological sensing; demonstrated feasibility of integrating sensors into everyday objects; created novel simulation tools for accessibility education; developed frameworks for understanding interdependent collaboration between disabled and non-disabled users.

**Community Building**: Co-organized prestigious Dagstuhl Seminars; launched mobiCHAI workshop series creating new research community; brought together leaders from AI, accessibility, and HCI domains; fostered international collaborations across institutions and countries.

**Open Science**: Released hardware designs, software, and datasets under open licenses; lowered barriers for other researchers to build upon our work; contributed to democratizing access to wearable sensing technologies; followed Open Source Hardware Association best practices.

**Real-World Deployments**: Validated prototypes in authentic contexts (rainy weather, running routes, work environments, café employment); established partnerships with disabled communities; demonstrated practical applicability beyond academic contributions; informed design of future accessible IoT systems.

**Publication Venues**: Published at premier conferences including CHI (acceptance rate ~23-26%), UIST (~20-25%), and UbiComp, demonstrating peer-recognized quality and impact of the research.

### Evolution of Research Focus

The project evolved from initial technical explorations (2021: can we sense from umbrella handles?) through expansion of capabilities (2022: simulation tools, theoretical foundations) to community engagement (2023: real-world deployments, co-design) and finally platform development and dissemination (2024-2025: open-source releases, community building, synthesis). This progression reflects maturation from proof-of-concept work to validated, deployable systems that others can build upon.

### Key Research Themes Over Time

**Consistent threads**: Physiological sensing, inclusive design, real-world evaluation, open-source philosophy

**Expanding domains**: Visual accessibility → haptic feedback → vocal sensing → cognitive augmentation → assistive robotics

**Methodological evolution**: Individual prototypes → community partnerships → open platforms → international workshops

---

⭐ = Featured publication (high impact, top-tier venue)

[View all publications →](/publications)
[Explore research outcomes →](/research)
[Learn about project background →](/background)