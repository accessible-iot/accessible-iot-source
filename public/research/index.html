<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Towards Accessibility Assessment Tools for the Internet of Things"><title>Research | Accessible IoT</title><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=/css/main.css></head><body><div class=site-wrapper><aside class=sidebar><div class=sidebar-header><a href=/ class=site-title>Accessible IoT</a></div><nav class=sidebar-nav><ul><li><a href=/>Home</a></li><li><a href=/research/ class=active>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></aside><header class=mobile-header><a href=/ class=mobile-title>Accessible IoT</a><nav class=mobile-nav><ul><li><a href=/>Home</a></li><li><a href=/research/ class=active>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></header><main class=main-content><div class=container><h1>Research</h1><p class=intro>Publications from the Accessible IoT project (2021-2025) under JST Presto Grant JPMJPR2132</p><div class=stats-grid><div class=stat-card><div class=stat-value>10</div><div class=stat-label>Publications</div></div><div class=stat-card><div class=stat-value>4</div><div class=stat-label>Years</div></div><div class=stat-card><div class=stat-value>7</div><div class=stat-label>Research Themes</div></div></div><section><h2>2025</h2><article class=publication-card><h3>BodyPursuits</h3><p class=publication-subtitle>Exploring Smooth Pursuit Gaze Interaction Based on Body Motion Targets</p><p class=publication-venue>ETRA 2025</p><p class=publication-authors>Anja Hansen, Sarah Makarem, Kai Kunze, Yexu Zhou, Michael Thomas Knierim, Christopher Clarke, Hans Gellersen, Michael Beigl, Tobias Röddiger</p><p><strong>Key Contribution:</strong> Novel gaze interaction technique based on smooth pursuit eye movements tracking body motion, enabling hands-free interaction</p><div class=publication-excerpt><p>This research explores how the natural eye movement pattern of smooth pursuit can be used for interaction with IoT systems and wearable devices. By tracking how users&rsquo; eyes follow their own body motions, the system creates new opportunities for hands-free control.</p><p>The technique has particular relevance for accessibility, enabling people with limited hand mobility to interact with technology using natural body movements and gaze. It represents an innovative approach to inclusive interface design in the context of ubiquitous computing.</p></div><div class=theme-badges><span class=theme-badge>cognitive-augmentation</span></div><div class=publication-links><a href=/papers/hansen2025bodypursuits.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3715669.3723110 target=_blank>DOI</a></div></article><article class=publication-card><h3>Eye-Tracking for Cognitive Well-Being</h3><p class=publication-subtitle>Balancing Detection and Ethical Feedback</p><p class=publication-venue>ETRA 2025</p><p class=publication-authors>Christopher Changmok Kim, Matthias Hoppe, Kai Kunze</p><p><strong>Key Contribution:</strong> Framework for ethical eye-tracking-based cognitive well-being monitoring that balances detection accuracy with user privacy and autonomy</p><div class=publication-excerpt><p>As eye-tracking becomes increasingly integrated into wearable devices and IoT systems, questions arise about how to ethically monitor and provide feedback about users&rsquo; cognitive states. This research addresses these concerns head-on, proposing design principles that prioritize user autonomy and well-being.</p><p>The work is particularly relevant for accessibility applications where cognitive monitoring could support people with attention difficulties, mental health challenges, or neurodivergent individuals, while respecting their privacy and agency.</p></div><div class=theme-badges><span class=theme-badge>cognitive-augmentation</span>
<span class=theme-badge>smart-eyewear</span></div><div class=publication-links><a href=/papers/kim2025eye.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3715669.3726817 target=_blank>DOI</a></div></article><article class=publication-card><h3>TIEboard: A Digital Educational Tool for Kids Geometric Learning</h3><p class=publication-venue>Proc. ACM IMWUT</p><p class=publication-authors>Arooj Zaidi, Giulia Barbareschi, Kai Kunze, Yun Suen Pai, Junichi Yamaoka</p><p><strong>Key Contribution:</strong> Interactive digital tool that makes geometric learning accessible and engaging for children</p><div class=publication-excerpt><p>TIEboard represents an innovative approach to making mathematics education more accessible and inclusive for children. By combining tangible interaction with digital feedback, the tool creates an engaging learning environment that supports diverse learning styles.</p><p>The research demonstrates how IoT-enabled educational tools can bridge the gap between abstract mathematical concepts and concrete, hands-on learning experiences.</p></div><div class=theme-badges><span class=theme-badge>educational-tools</span>
<span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/zaidi2025tieboard.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3729478 target=_blank>DOI</a></div></article><article class="publication-card featured"><h3>Sticking With Electronics for Crafting Practices</h3><p class=publication-subtitle>An Inclusive Approach to Promote Making Literacy Among Older Adults</p><p class=publication-venue>CHI 2025</p><p class=publication-authors>Giulia Barbareschi, Chihiro Sato, Seray Senyer, Michael Pan Junpeng, Jianrui Zhao, Dunya Chen, Kirsten Ellis, Kai Kunze</p><p><strong>Key Contribution:</strong> Inclusive approach to teaching electronics and making skills to older adults through crafting practices</p><div class=publication-excerpt><p>This work addresses the digital divide by making electronics and IoT creation accessible to older adults. Through carefully designed crafting activities that incorporate electronics, the research shows how older adults can develop technical literacy while engaging in creative, meaningful activities.</p><p>The findings have important implications for inclusive design in IoT, showing that with appropriate support and methods, technology creation can be made accessible across age groups and technical backgrounds.</p></div><div class=theme-badges><span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/barbareschi2025sticking.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3706598.3714234 target=_blank>DOI</a></div></article><article class=publication-card><h3>Cuddle-Fish: Exploring a Soft Floating Robot with Flapping Wings for Physical Interactions</h3><p class=publication-venue>AHs 2025</p><p class=publication-authors>Mingyang Xu, Jiayi Shao, Yulan Ju, Ximing Shen, Qingyuan Gao, Weijen Chen, Qing Zhang, Yun Suen Pai, Giulia Barbareschi, Matthias Hoppe, Kouta Minamizawa, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel soft floating robot design for safe and engaging physical interaction</p><div class=publication-excerpt><p>Cuddle-Fish presents an innovative soft floating robot with flapping wings designed for safe physical interactions. The soft materials and gentle motion make it suitable for therapeutic and assistive applications, particularly in contexts requiring calming, non-threatening robotic presence.</p></div><div class=theme-badges><span class=theme-badge>assistive-robotics</span></div><div class=publication-links><a href=/papers/xu2025cuddle.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3745900.3746080 target=_blank>DOI</a></div></article></section><section><h2>2024</h2><article class="publication-card featured"><h3>OpenEarable ExG: Open-Source Hardware for Ear-Based Biopotential Sensing Applications</h3><p class=publication-venue>UbiComp 2024</p><p class=publication-authors>Philipp Lepold, Tobias Röddiger, Tobias King, Kai Kunze, Christoph Maurer, Michael Beigl</p><p><strong>Key Contribution:</strong> Open-source hardware platform for ear-based biopotential sensing, enabling accessible IoT health monitoring</p><div class=publication-excerpt><p>This paper introduces OpenEarable ExG, an innovative open-source hardware platform that democratizes ear-based biopotential sensing. By making the designs and schematics freely available, the research enables a wide range of applications in health monitoring, cognitive state detection, and accessibility tools.</p><p>The platform supports various biopotential signals including EOG (electrooculography), EMG (electromyography), and ECG (electrocardiography), all captured from the ear region. This positions OpenEarable as a key enabling technology for the Internet of Things in healthcare and accessibility contexts.</p></div><div class=theme-badges><span class=theme-badge>wearable-iot</span></div><div class=publication-links><a href=/papers/lepold2024open.pdf target=_blank>PDF</a></div></article><article class="publication-card featured"><h3>Speech is Silver, Silence is Golden</h3><p class=publication-subtitle>Analyzing Micro-communication Strategies between Visually Impaired Runners and their Guides</p><p class=publication-venue>CHI 2024</p><p class=publication-authors>Giulia Barbareschi, Tarika Kumar, Christopher Changmok Kim, George Chernyshov, Kai Kunze</p><p><strong>Key Contribution:</strong> First study on non-verbal communication strategies between visually impaired runners and sighted guides</p><div class=publication-excerpt><p>This groundbreaking research explores the subtle communication patterns that enable visually impaired runners and their guides to move together effectively. The study reveals intricate verbal and non-verbal signaling strategies that have developed organically in the running community, providing insights for designing better assistive technologies for sports and physical activities.</p><p>Key findings include the importance of silence as a form of communication, indicating smooth coordination, and the role of micro-adjustments in maintaining synchronization between runner and guide.</p></div><div class=theme-badges><span class=theme-badge>visual-accessibility</span>
<span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/barbareschi2024speech.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3613904.3642000 target=_blank>DOI</a></div></article></section><section><h2>2023</h2><article class=publication-card><h3>Soma Express Kit</h3><p class=publication-subtitle>Understanding the Somaesthetic Experience of People with Visual Impairment</p><p class=publication-venue>IoT 2023</p><p class=publication-authors>Michi Kanda, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel IoT toolkit that leverages heightened somatosensory capacities of people with visual impairments for cross-ability interaction</p><div class=publication-excerpt><p>This research introduces an innovative approach to understanding and sharing the embodied experiences of people with visual impairments. The Soma Express Kit uses IoT sensors and multi-sensory feedback to create new channels of communication between people with and without visual impairments.</p><p>By embracing the somaesthetic potential of people with visual impairments, this work fosters empathy and enables richer collaborative cross-ability interactions. The toolkit represents a significant contribution to inclusive IoT design, moving beyond traditional assistive technology paradigms.</p></div><div class=theme-badges><span class=theme-badge>visual-accessibility</span>
<span class=theme-badge>wearable-iot</span></div><div class=publication-links><a href=/papers/kanda2023soma.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3627050.3631571 target=_blank>DOI</a></div></article><article class="publication-card featured"><h3>I am both here and there</h3><p class=publication-subtitle>Parallel Control of Multiple Robotic Avatars by Disabled Workers in a Café</p><p class=publication-venue>CHI 2023</p><p class=publication-authors>Giulia Barbareschi, Midori Kawaguchi, Hiroaki Kato, Masato Nagahiro, Kazuaki Takeuchi, Yoshifumi Shiiba, Shunichi Kasahara, Kai Kunze, Kouta Minamizawa</p><p><strong>Key Contribution:</strong> Demonstrated that disabled workers can effectively control multiple robotic avatars simultaneously in a real café environment</p><div class=publication-excerpt><p>A groundbreaking study conducted in a real café environment where disabled workers operated multiple robotic avatars in parallel. The research demonstrates that people with disabilities possess specific competencies that enhance their ability to manage multiple embodied presences simultaneously.</p><p>The findings have significant implications for employment opportunities and workplace accessibility, showing how assistive robotics can create new forms of meaningful work for people with mobility impairments.</p><p>This work was featured in multiple accessibility newsletters and demonstrates the practical application of IoT and robotics in creating inclusive workspaces.</p></div><div class=theme-badges><span class=theme-badge>assistive-robotics</span>
<span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/barbareschi2023both.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3544548.3581124 target=_blank>DOI</a></div></article></section><section><h2>2022</h2><article class="publication-card featured"><h3>Seeing our Blind Spots</h3><p class=publication-subtitle>Smart Glasses-based Simulation to Increase Design Students' Awareness of Visual Impairment</p><p class=publication-venue>UIST 2022</p><p class=publication-authors>Qing Zhang, Giulia Barbareschi, Yifei Huang, Juling Li, Yun Suen Pai, Jamie Ward, Kai Kunze</p><p><strong>Key Contribution:</strong> Dynamic smart glasses-based simulation system that considers eye movements, improving accessibility awareness training</p><div class=publication-excerpt><p>Traditional visual impairment simulation tools are static and fail to account for dynamic eye movements. This research introduces a smart glasses-based system that provides realistic, dynamic simulations of various visual impairments.</p><p>The system was evaluated with design students, demonstrating significant improvements in their awareness and understanding of visual accessibility challenges. Questionnaires and qualitative feedback confirmed that the dynamic, eye-movement-aware simulation helped participants develop more empathetic and informed approaches to inclusive design.</p><p>This work bridges the gap between accessibility theory and practice, providing tangible tools for educating the next generation of designers about inclusive IoT systems.</p></div><div class=theme-badges><span class=theme-badge>smart-eyewear</span>
<span class=theme-badge>visual-accessibility</span></div><div class=publication-links><a href=/papers/zhang2022seeing.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3526113.3545687 target=_blank>DOI</a></div></article></section></div></main></div></body></html>