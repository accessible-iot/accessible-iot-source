<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Smart-Eyewear on Accessible IoT</title><link>https://accessible-iot.org/themes/smart-eyewear/</link><description>Recent content in Smart-Eyewear on Accessible IoT</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 02 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://accessible-iot.org/themes/smart-eyewear/index.xml" rel="self" type="application/rss+xml"/><item><title>Eye-Tracking for Cognitive Well-Being</title><link>https://accessible-iot.org/publications/kim2025eye/</link><pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate><guid>https://accessible-iot.org/publications/kim2025eye/</guid><description>&lt;p&gt;As eye-tracking becomes increasingly integrated into wearable devices and IoT systems, questions arise about how to ethically monitor and provide feedback about users&amp;rsquo; cognitive states. This research addresses these concerns head-on, proposing design principles that prioritize user autonomy and well-being.&lt;/p&gt;
&lt;p&gt;The work is particularly relevant for accessibility applications where cognitive monitoring could support people with attention difficulties, mental health challenges, or neurodivergent individuals, while respecting their privacy and agency.&lt;/p&gt;</description></item><item><title>Seeing our Blind Spots</title><link>https://accessible-iot.org/publications/zhang2022seeing/</link><pubDate>Sat, 29 Oct 2022 00:00:00 +0000</pubDate><guid>https://accessible-iot.org/publications/zhang2022seeing/</guid><description>&lt;p&gt;Traditional visual impairment simulation tools are static and fail to account for dynamic eye movements. This research introduces a smart glasses-based system that provides realistic, dynamic simulations of various visual impairments.&lt;/p&gt;
&lt;p&gt;The system was evaluated with design students, demonstrating significant improvements in their awareness and understanding of visual accessibility challenges. Questionnaires and qualitative feedback confirmed that the dynamic, eye-movement-aware simulation helped participants develop more empathetic and informed approaches to inclusive design.&lt;/p&gt;</description></item></channel></rss>